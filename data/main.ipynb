{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Creating the rule set"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "This notebook is about creating the rule set for diversity sensitive suggestions for the LanguageTool server. Some sources will be pulled from the internet and will be processed to fit the format as well as possible."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The notebook uses [Poetry](https://python-poetry.org/) for reproducibility. For running the notebook in an environment where the appropriate dependencies are installed, run `poetry install` and then `poetry run jupyter notebook` to start the notebook server."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "from os import path\n",
    "from shared import add_to_dict, log\n",
    "from typing import *\n",
    "import cache_magic\n",
    "import copy_files\n",
    "import datetime\n",
    "import io\n",
    "import pandas as pd\n",
    "import random\n",
    "import re\n",
    "import requests\n",
    "import spacy\n",
    "import subprocess\n",
    "import wayback"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "data_dir = \"wordlists\" # where the downloaded and processed data will be saved\n",
    "fetch_data = False # whether to re-download the files"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "nlp = spacy.load(\"de_core_news_sm\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "def number(s: str) -> List[str]:\n",
    "    return nlp(s)[0].morph.get(\"Number\")\n",
    "\n",
    "assert number(\"Bundeskanzlerin\") == [\"Sing\"]\n",
    "assert number(\"Bundeskanzlerinnen\") == [\"Plur\"]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "def is_word(word: str) -> bool:\n",
    "    return True\n",
    "#     return len(gn.sysnsets(word)) > 0\n",
    "\n",
    "# assert is_word(\"Baum\") == True\n",
    "# assert is_word(\"Bäum\") == False"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "data = {\n",
    "    \"sg\": {},\n",
    "    \"pl\": {},\n",
    "}\n",
    "\n",
    "def strip_spaces(a):\n",
    "    s = re.sub(\"  +|\\\"|'\", \" \", a)\n",
    "    a = re.sub(\"^ | $|[.,:;!?]\", \"\", a)\n",
    "    return a\n",
    "\n",
    "def add_to_data(pattern, numerus, suggestions):\n",
    "    pattern = strip_spaces(pattern)\n",
    "    if numerus == \"sg\":\n",
    "        add_to_dict(pattern, suggestions, data[\"sg\"])\n",
    "    elif numerus == \"pl\":\n",
    "        add_to_dict(pattern, suggestions, data[\"pl\"])\n",
    "    elif numerus == \"unknown\":\n",
    "        if \"Sing\" in number(pattern):\n",
    "            add_to_data(pattern, \"sg\", suggestions)\n",
    "        if \"Plur\" in number(pattern):\n",
    "            add_to_data(pattern, \"pl\", suggestions)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## The Microsoft / Vienna catalog"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "%cache mem = wb.get_memento(\"https://www.data.gv.at/katalog/dataset/15d6ede8-f128-4fcd-aa3a-4479e828f477/resource/804f6db1-add7-4480-b4d0-e52e61c48534/download/worttabelle.csv\", datetime=datetime.datetime(2021, 9, 13, tzinfo=datetime.timezone.utc), exact=False)\n",
    "text = re.sub(\";;\\r\\n\", \"\\n\", mem.content.decode(\"utf-8\"))\n",
    "df = pd.read_csv(io.StringIO(text))\n",
    "df = df[df[\"Hauptwort\"].notna()]\n",
    "df.to_csv(path.join(data_dir, \"vienna_catalog.csv\"), index=False)\n",
    "df"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "creating new value for variable 'mem'\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Laenge</th>\n",
       "      <th>Hauptwort</th>\n",
       "      <th>Vorschlag</th>\n",
       "      <th>Binnen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "      <td>Verantwortlicher für Informationssicherheit (C...</td>\n",
       "      <td>CISO</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Verantwortlicher für Informationssicherheit (C...</td>\n",
       "      <td>Verantwortliche bzw. Verantwortlicher für Info...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>45</td>\n",
       "      <td>Diplomierte Gesundheits- und Krankenschwester</td>\n",
       "      <td>Diplomiertes Krankenpflegepersonal</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>43</td>\n",
       "      <td>Unabhängiger Bedienstetenschutzbeauftragter</td>\n",
       "      <td>Unabhängige Bedienstetenschutzbeauftragte bzw....</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>39</td>\n",
       "      <td>Kontrakt- und Berichtswesenbeauftragter</td>\n",
       "      <td>Kontrakt- und Berichtswesenbeauftragte bzw. -b...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2266</th>\n",
       "      <td>4</td>\n",
       "      <td>Koch</td>\n",
       "      <td>Köchin bzw. Koch</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2267</th>\n",
       "      <td>4</td>\n",
       "      <td>Star</td>\n",
       "      <td>Berühmtheit</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2268</th>\n",
       "      <td>4</td>\n",
       "      <td>User</td>\n",
       "      <td>Userin bzw. User</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2269</th>\n",
       "      <td>4</td>\n",
       "      <td>User</td>\n",
       "      <td>UserInnen</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2270</th>\n",
       "      <td>2</td>\n",
       "      <td>DJ</td>\n",
       "      <td>DJane bzw. DJ</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2268 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Laenge                                          Hauptwort  \\\n",
       "0        50  Verantwortlicher für Informationssicherheit (C...   \n",
       "1        50  Verantwortlicher für Informationssicherheit (C...   \n",
       "2        45      Diplomierte Gesundheits- und Krankenschwester   \n",
       "3        43        Unabhängiger Bedienstetenschutzbeauftragter   \n",
       "4        39            Kontrakt- und Berichtswesenbeauftragter   \n",
       "...     ...                                                ...   \n",
       "2266      4                                               Koch   \n",
       "2267      4                                               Star   \n",
       "2268      4                                               User   \n",
       "2269      4                                               User   \n",
       "2270      2                                                 DJ   \n",
       "\n",
       "                                              Vorschlag Binnen  \n",
       "0                                                  CISO      N  \n",
       "1     Verantwortliche bzw. Verantwortlicher für Info...      N  \n",
       "2                    Diplomiertes Krankenpflegepersonal      N  \n",
       "3     Unabhängige Bedienstetenschutzbeauftragte bzw....      N  \n",
       "4     Kontrakt- und Berichtswesenbeauftragte bzw. -b...      N  \n",
       "...                                                 ...    ...  \n",
       "2266                                   Köchin bzw. Koch      N  \n",
       "2267                                        Berühmtheit      N  \n",
       "2268                                   Userin bzw. User      N  \n",
       "2269                                          UserInnen      Y  \n",
       "2270                                      DJane bzw. DJ      N  \n",
       "\n",
       "[2268 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "for (_, _, pattern, suggestion, binnenI) in df.to_records():\n",
    "    if binnenI == \"Y\":\n",
    "        suggestion = re.sub(r\"([a-zäöüß])I\", r\"\\1*i\", suggestion)\n",
    "    if not complicated(pattern) or complicated(suggestion):\n",
    "        if re.findall(\"[iI]n($| )\", suggestion) != []:\n",
    "            add_to_data(pattern, \"sg\", [suggestion])\n",
    "        elif re.findall(\"[iI]nnen$\", suggestion) != []:\n",
    "            add_to_data(pattern, \"pl\", [suggestion])\n",
    "        else:\n",
    "            add_to_data(pattern, \"unknown\", [suggestion])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## The _DeReKo_ data set\n",
    "\n",
    "We extract some data from the \"Deutsche ReferenzKorpus\". \n",
    "\n",
    "Queries:\n",
    "- Internal I: `:Ab:*?Innen`: 241k tokens, 18k types (`:Ab:*?In` and `:Ab:#REG(^[A-ZÄÖÜ][a-zäöüß]+In(nen)?$)` throw errors)\n",
    "- Slash: `#REG(^[A-ZÄÖÜ][a-zäöüß]+\\/in(nen)?$)`: 136k tokens, 9k types\n",
    "- Star: `#REG(^[A-ZÄÖÜ][a-zäöüß]+\\*in(nen)?$)`: 48k tokens, 5k types\n",
    "- Colon: `#REG(^[A-ZÄÖÜ][a-zäöüß]+:in(nen)?$)`: 10k tokens, 3k types\n",
    "- Underscore: `#REG(^[A-ZÄÖÜ][a-zäöüß]+_in(nen)?$)`: 3k tokens, 1k types\n",
    "- Interpunct: `#REG(^[A-ZÄÖÜ][a-zäöüß]+·in(nen)?$)`: 4(!) matches\n",
    "- Brackets: `*?\\(In\\)`, `*?\\(Innen\\)`, `#REG(\\(in(nen)\\))` and similar queries throw errors"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "There is no machine-readable download on DeReKo to our knowledge, so we process the files a bit:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "match_properly_gendered_word = r\"[A-ZÄÖÜ][a-zäöüß]{3,}(([/*:_·(]in(nen)?\\)?)|In(nen)?)\"\n",
    "\n",
    "def is_properly_gendered_word(word: str) -> bool:\n",
    "    return re.findall(r\"^[A-ZÄÖÜ][a-zäöüß]{3,}(([/*:_·(]in(nen)?\\)?)|In(nen)?)$\", word) != []\n",
    "\n",
    "assert is_properly_gendered_word(\"Bundeskanzler:innen\") == True\n",
    "assert is_properly_gendered_word(\"BundeskanzlerIn\") == True\n",
    "assert is_properly_gendered_word(\"Bundeskanzler*Innen\") == False"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "def dereko_to_csv(filename: str):\n",
    "    text = open(path.join(data_dir, \"dereko\", filename + '.txt')).read()\n",
    "    lines = text.split(\"\\n\")[20:]\n",
    "    words = [re.match(match_properly_gendered_word, line)[0] for line in lines if re.match(match_properly_gendered_word, line)]\n",
    "    open(path.join(data_dir, \"dereko\", filename + '.csv'), \"w\").write(\"\\n\".join(words))\n",
    "    return words\n",
    "\n",
    "assert 'Bundeskanzler*in' in dereko_to_csv(\"star\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "dereko_to_csv(\"internal-i\")[:5]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['AachenerInnen',\n",
       " 'AbbiegerInnen',\n",
       " 'AbbrecherInnen',\n",
       " 'AbeitsplatzbesitzerInnen',\n",
       " 'AbendländerInnen']"
      ]
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "dereko_to_csv(\"colon\")[:5]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['Abenteurer:innen',\n",
       " 'Abiturient:innen',\n",
       " 'Ablehner:innen',\n",
       " 'Abnehmer:innen',\n",
       " 'Abonennt:innen']"
      ]
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "def is_gendered_plural(word: str) -> str:\n",
    "    return re.findall(r\"[Ii]nnen\\)?$\", word) != []\n",
    "\n",
    "assert is_gendered_plural(\"Bundeskanzler*in\") == False\n",
    "assert is_gendered_plural(\"Bundesminister/in\") == False\n",
    "assert is_gendered_plural(\"Bundesminister*innen\") == True"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "def ungender(word: str) -> str:\n",
    "    return re.sub(r\"[/*:_·()]?[Ii]n(n(en))?$\", \"\", word)\n",
    "\n",
    "assert ungender(\"Bundeskanzler*in\") == \"Bundeskanzler\"\n",
    "assert ungender(\"Bundesminister*innen\") == \"Bundesminister\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "def regender(word: str, symbol: str) -> str:\n",
    "    # replace gender symbol with other gender symbol\n",
    "    return re.sub(r\"[/*:_·()]?-?[Ii]n(nen)?$\", r\"{}in\\1\".format(symbol), word)\n",
    "\n",
    "assert regender(\"Bundeskanzler*in\", \"*\") == \"Bundeskanzler*in\"\n",
    "assert regender(\"Bundeskanzler:in\", \"*\") == \"Bundeskanzler*in\"\n",
    "assert regender(\"Bundeskanzler_in\", \"*\") == \"Bundeskanzler*in\"\n",
    "assert regender(\"Bundeskanzler/in\", \"*\") == \"Bundeskanzler*in\"\n",
    "assert regender(\"Bundeskanzler/-in\", \"*\") == \"Bundeskanzler*in\"\n",
    "assert regender(\"Bundeskanzler·in\", \"*\") == \"Bundeskanzler*in\"\n",
    "assert regender(\"BundeskanzlerIn\", \"*\") == \"Bundeskanzler*in\"\n",
    "assert regender(\"BundesministerIn\", \"*\") == \"Bundesminister*in\"\n",
    "assert regender(\"BundesministerInnen\", \"*\") == \"Bundesminister*innen\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "count_dict = {}\n",
    "def add_to_count_dict(key, number, val):\n",
    "    if (key, number, val) in count_dict.keys():\n",
    "        count_dict[(key, number, val)] += 1\n",
    "    else:\n",
    "        count_dict[(key, number, val)] = 1"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "dereko_lists = [dereko_to_csv(a) for a in [\"colon\", \"internal-i\", \"interpunct\", \"slash\", \"star\", \"underscore\"]]\n",
    "for l in dereko_lists:\n",
    "    for word in l:\n",
    "        if is_properly_gendered_word(word):\n",
    "            key = ungender(word)\n",
    "            suggestion = regender(word, \"*\")\n",
    "            if is_gendered_plural(suggestion):\n",
    "                if is_word(key):\n",
    "                    add_to_count_dict(key, \"pl\", suggestion)\n",
    "                if is_word(key):\n",
    "                    add_to_count_dict(key + \"en\", \"pl\", suggestion)\n",
    "            else:  \n",
    "                add_to_count_dict(key, \"sg\", suggestion)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "dereko_unified = {}\n",
    "for (key, number, val), count in count_dict.items():\n",
    "    if count >= 3:\n",
    "        add_to_dict(key, [val], dereko_unified)\n",
    "        add_to_data(key, number, [val])\n",
    "assert 'Bundeskanzler' in data[\"sg\"].keys()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "open(path.join(data_dir, \"dereko\", \"unified.csv\"), \"w\").write(\"\\n\".join(sorted([a[0] for a in dereko_unified.values()])))"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "50152"
      ]
     },
     "metadata": {},
     "execution_count": 35
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Because we cannot use regular expressions to enhance the \"internal i\" query directly on DeReKo (due to issues with case sensitivity), we perform some postprocessing for the results."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## The _retext equality_ data set"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We skip this data set for now because many of the rules cannot be transformed to simple replacement rules."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "source": [
    "# responses = {}\n",
    "# for topic in topics:\n",
    "#     responses[topic] = requests.get(\"https://raw.githubusercontent.com/retextjs/retext-equality/main/data/en/{}.yml\".format(topic)).text\n",
    "    "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "source": [
    "# for topic in topics:\n",
    "#     data = yaml.safe_load(responses[topic])\n",
    "#     for row in data:\n",
    "#         considerate = row[\"considerate\"]\n",
    "#         inconsiderate = row[\"inconsiderate\"]\n",
    "#         if type(considerate) == str:\n",
    "#             rules[considerate] = inconsiderate\n",
    "#         elif type(considerate) == list:\n",
    "#             for phrase in considerate:\n",
    "#                 rules[phrase] = inconsiderate"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "source": [
    "# open(path.join(\"data\", \"retext_equality_raw.yaml\"), \"w\").write(yaml.dump(data))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Custom rules"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We add some custom rules that we have written ourselves, inspired in part by the _retext-equality_ data set. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "source": [
    "custom_xml = open(path.join(data_dir, \"custom_list_disability.xml\")).read()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Conversion to proper LanguageTool XML format\n",
    "\n",
    "The LanguageTool rule format is described [over here](https://web.archive.org/web/20210910183442/https://dev.languagetool.org/development-overview) and [here](https://dev.languagetool.org/tips-and-tricks)."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We devise a function to convert a _geschickt gendern_ entry to a XML LanguageTool entry."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "source": [
    "re.findall(r\"\\w+|\\W+\", \"Wiener*innen\")"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['Wiener', '*', 'innen']"
      ]
     },
     "metadata": {},
     "execution_count": 40
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def startupper(s: str) -> str:\n",
    "    return s[0].capitalize() + s[1:]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "assert startupper(\"absolvierende Person\") == \"Absolvierende Person\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def rule_to_xml(pattern: str, numerus: str, suggestions: List[str]) -> str:\n",
    "    id = re.sub(\"\\s\", \"_\", pattern + \"_\" + numerus)\n",
    "    id = re.sub(\"[^A-ZÄÖÜa-zäöüß_]\", \"\", id)\n",
    "    if numerus == \"sg\":\n",
    "        postag_attributes = 'postag=\".*:SIN:.*\" postag_regexp=\"yes\" '\n",
    "    elif numerus == \"pl\":\n",
    "        postag_attributes = 'postag=\".*:PLU:.*\" postag_regexp=\"yes\" '\n",
    "    replaced_tokens = \"\".join([\n",
    "        '<token inflected=\"yes\" {}>{}</token>'.format(postag_attributes, token) \n",
    "        for token in pattern.split(\" \")])\n",
    "    suggestions_ = \",\\n\\t\\t\".join([\"<suggestion>{}</suggestion>\".format(s) for s in suggestions])\n",
    "    antipatterns = \"\\n\\t\\t\".join(\n",
    "        [\"<antipattern>\\n\\t\\t{}\\n\\t\\t</antipattern>\".format(\"\\n\\t\\t\".join(\n",
    "            ['<token inflected=\"yes\">{}</token>'.format(token) for token in re.findall(r\"\\w+|[.,:;*_·/]\", s)]\n",
    "        )) for s in suggestions])\n",
    "    corrections = \"|\".join([startupper(s) for s in suggestions])\n",
    "    return \"\"\"\n",
    "    <rule id=\"{id}\" name=\"{pattern}\">\n",
    "        {antipatterns}\n",
    "        <pattern>{replaced_tokens}</pattern>\n",
    "        <message>\n",
    "        Mit dem generischen Maskulinum werden nicht alle Geschlechter gleichermaßen assoziiert. Vielleicht passt einer der folgenden neutralen Begriffe besser: \n",
    "        {suggestions}\n",
    "        </message>\n",
    "        <short>Generisches Maskulinum</short>\n",
    "        <example correction=\"{corrections}\"><marker>{pattern}</marker></example>\n",
    "    </rule>\n",
    "    \"\"\".format(id=id, pattern=pattern, antipatterns=antipatterns, replaced_tokens=replaced_tokens, suggestions=suggestions_, corrections=corrections)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# print(rule_to_xml(\"Wiener\", \"pl\", data[\"sg\"][\"pl\"]))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "xml = custom_xml\n",
    "for numerus in [\"sg\", \"pl\"]:\n",
    "    xml += \"\\n\\n\" + \"\".join([rule_to_xml(key, numerus, val) for key, val in data[numerus].items()])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Injecting the rules to the existing LanguageTool rule file"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "custom_filename = \"grammar_custom.xml\"\n",
    "open(path.join(data_dir, custom_filename), \"w\").write(xml)\n",
    "copy_files.copy_files()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Validating and using the rules"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Running the LanguageTool rule validation:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# subprocess.run([\"./testrules.sh\", \"de\"], cwd=languagetool_path)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Starting LanguageTool:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# subprocess.run([\"java\", \"-jar\", path.join(languagetool_path, \"languagetool.jar\")])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "95bedcfbd13951187b69ec62defd411ebf202d41ec39fb8571ad901e1b39c86f"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.7 64-bit ('.venv': venv)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}