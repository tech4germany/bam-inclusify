{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Creating the rule set"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "This notebook is about creating the rule set for diversity sensitive suggestions for the LanguageTool server. Some sources will be pulled from the internet and will be processed to fit the format as well as possible."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The notebook uses [Poetry](https://python-poetry.org/) for reproducibility. For running the notebook in an environment where the appropriate dependencies are installed, run `poetry install` and then `poetry run jupyter notebook` to start the notebook server."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "source": [
    "import cache_magic\n",
    "import datetime\n",
    "import io\n",
    "from os import path\n",
    "import pandas as pd\n",
    "import yaml\n",
    "import random\n",
    "import re\n",
    "import requests\n",
    "import subprocess\n",
    "from typing import *\n",
    "import wayback"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "source": [
    "languagetool_path = path.join(\"..\", \"languagetool\", \"LanguageTool-5.4\") # adjust this to the folder of the LanguageTool release\n",
    "data_dir = \"wordlists\" # where the downloaded and processed data will be saved\n",
    "datasets = []"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## The data set by _geschickt gendern_"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "source": [
    "wb = client = wayback.WaybackClient()\n",
    "%cache mem = wb.get_memento(\"https://geschicktgendern.de/download/1642/\", datetime=datetime.datetime(2021, 9, 11, tzinfo=datetime.timezone.utc), exact=False)\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "creating new value for variable 'mem'\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "source": [
    "df = pd.read_excel(mem.content, header=None, names=[\"ungendered\", \"gendered\"], skiprows=3, usecols=[1,2])\n",
    "df.sort_values(by=\"ungendered\")\n",
    "df"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ungendered</th>\n",
       "      <th>gendered</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;div id=\"A\"&gt;&lt;b&gt;A&lt;/b&gt;&lt;div&gt;</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Abbrecherquote</td>\n",
       "      <td>Abbruchquote</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Abenteurer (sg.)</td>\n",
       "      <td>Waghals; abenteuerliebende Person; abenteuerlu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Abgänger</td>\n",
       "      <td>absolvierende Person; Abschluss innehabende Pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Abiturient</td>\n",
       "      <td>Abitur ablegende Person; Person, die Abitur macht</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1814</th>\n",
       "      <td>Zuschauer (pl.)</td>\n",
       "      <td>Publikum; Zuschauende</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1815</th>\n",
       "      <td>Zuschauerquote</td>\n",
       "      <td>Einschaltquote</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1816</th>\n",
       "      <td>Zuschauerzahl</td>\n",
       "      <td>Publikumszahl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1817</th>\n",
       "      <td>Zuständiger</td>\n",
       "      <td>zuständige Person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1818</th>\n",
       "      <td>Zuwanderer (pl.)</td>\n",
       "      <td>Zugewanderte; Personen mit Migrationshintergru...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1819 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     ungendered  \\\n",
       "0     <div id=\"A\"><b>A</b><div>   \n",
       "1                Abbrecherquote   \n",
       "2              Abenteurer (sg.)   \n",
       "3                      Abgänger   \n",
       "4                    Abiturient   \n",
       "...                         ...   \n",
       "1814            Zuschauer (pl.)   \n",
       "1815             Zuschauerquote   \n",
       "1816              Zuschauerzahl   \n",
       "1817                Zuständiger   \n",
       "1818           Zuwanderer (pl.)   \n",
       "\n",
       "                                               gendered  \n",
       "0                                                   NaN  \n",
       "1                                          Abbruchquote  \n",
       "2     Waghals; abenteuerliebende Person; abenteuerlu...  \n",
       "3     absolvierende Person; Abschluss innehabende Pe...  \n",
       "4     Abitur ablegende Person; Person, die Abitur macht  \n",
       "...                                                 ...  \n",
       "1814                              Publikum; Zuschauende  \n",
       "1815                                     Einschaltquote  \n",
       "1816                                      Publikumszahl  \n",
       "1817                                  zuständige Person  \n",
       "1818  Zugewanderte; Personen mit Migrationshintergru...  \n",
       "\n",
       "[1819 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "execution_count": 131
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We drop rows like the first one, where there is merely some HTML description but no value."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "source": [
    "df = df[df[\"gendered\"].notna()]\n",
    "df.to_csv(path.join(data_dir, \"geschicktgendern.csv\"), index=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We convert the singular / plural annotations to part-of-speech tags for LanaguageTool:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "source": [
    "def postag(key: Optional[str]) -> str:\n",
    "    numerus = re.search(\"\\(.*(sg|pl)\\.\\)\", key)\n",
    "    if numerus:\n",
    "        if numerus[1] == \"sg\":\n",
    "            return \".*SIN.*\"\n",
    "        if numerus[1] == \"pl\":\n",
    "            return \".*PLU.*\"\n",
    "    else: \n",
    "        return None"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "source": [
    "print(postag(\"Baum (grün; sg.)\"))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      ".*SIN.*\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "source": [
    "df.loc[13]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "ungendered            Absolventenvorsprechen [Schauspielschule]\n",
       "gendered      <a href=\"https://geschicktgendern.de/kontakt\">...\n",
       "Name: 13, dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 135
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We see that some suggestions are annotated by HTML, for example with the annotation that there is no good suggestion yet. This is too complicated for us to handle, so we will drop such suggestions."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The `gendered` column often contains multiple variants that are separated by a semicolon. We want to capture this."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "source": [
    "records = df.to_records()\n",
    "data = []\n",
    "for (_, key, val) in records:\n",
    "    unannotated_suggestions = [x for x in val.split(\"; \") if  not '<' in x]\n",
    "    if not ('<' in key or \"...\" in key) and len(unannotated_suggestions) > 0:\n",
    "        data.append({\n",
    "            \"pattern\": re.sub(\" ?\\[.*\\]\", \"\", re.sub(\" ?\\(.*\\)\", \"\", key)),\n",
    "            \"postag\": postag(key),\n",
    "            \"suggestions\": unannotated_suggestions,\n",
    "            \"url\": \"https://geschicktgendern.de/\"\n",
    "        })\n",
    "        \n",
    "print(\"This reduces the number of rules from {} to {}.\".format(len(records), len(data)))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "This reduces the number of rules from 1792 to 1558.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Rows like this one contain values that include formatting. We drop these values, but not the whole row."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "source": [
    "datasets.append(data)\n",
    "data = None"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## The Microsoft / Vienna catalog"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "source": [
    "%cache mem = wb.get_memento(\"https://www.data.gv.at/katalog/dataset/15d6ede8-f128-4fcd-aa3a-4479e828f477/resource/804f6db1-add7-4480-b4d0-e52e61c48534/download/worttabelle.csv\", datetime=datetime.datetime(2021, 9, 13, tzinfo=datetime.timezone.utc), exact=False)\n",
    "text = re.sub(\";;\\r\\n\", \"\\n\", mem.content.decode(\"utf-8\"))\n",
    "df = pd.read_csv(io.StringIO(text))\n",
    "df = df[df[\"Hauptwort\"].notna()]\n",
    "df.to_csv(path.join(data_dir, \"vienna_catalog.csv\"), index=False)\n",
    "df"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "creating new value for variable 'mem'\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Laenge</th>\n",
       "      <th>Hauptwort</th>\n",
       "      <th>Vorschlag</th>\n",
       "      <th>Binnen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "      <td>Verantwortlicher für Informationssicherheit (C...</td>\n",
       "      <td>CISO</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Verantwortlicher für Informationssicherheit (C...</td>\n",
       "      <td>Verantwortliche bzw. Verantwortlicher für Info...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>45</td>\n",
       "      <td>Diplomierte Gesundheits- und Krankenschwester</td>\n",
       "      <td>Diplomiertes Krankenpflegepersonal</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>43</td>\n",
       "      <td>Unabhängiger Bedienstetenschutzbeauftragter</td>\n",
       "      <td>Unabhängige Bedienstetenschutzbeauftragte bzw....</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>39</td>\n",
       "      <td>Kontrakt- und Berichtswesenbeauftragter</td>\n",
       "      <td>Kontrakt- und Berichtswesenbeauftragte bzw. -b...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2266</th>\n",
       "      <td>4</td>\n",
       "      <td>Koch</td>\n",
       "      <td>Köchin bzw. Koch</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2267</th>\n",
       "      <td>4</td>\n",
       "      <td>Star</td>\n",
       "      <td>Berühmtheit</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2268</th>\n",
       "      <td>4</td>\n",
       "      <td>User</td>\n",
       "      <td>Userin bzw. User</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2269</th>\n",
       "      <td>4</td>\n",
       "      <td>User</td>\n",
       "      <td>UserInnen</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2270</th>\n",
       "      <td>2</td>\n",
       "      <td>DJ</td>\n",
       "      <td>DJane bzw. DJ</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2268 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Laenge                                          Hauptwort  \\\n",
       "0        50  Verantwortlicher für Informationssicherheit (C...   \n",
       "1        50  Verantwortlicher für Informationssicherheit (C...   \n",
       "2        45      Diplomierte Gesundheits- und Krankenschwester   \n",
       "3        43        Unabhängiger Bedienstetenschutzbeauftragter   \n",
       "4        39            Kontrakt- und Berichtswesenbeauftragter   \n",
       "...     ...                                                ...   \n",
       "2266      4                                               Koch   \n",
       "2267      4                                               Star   \n",
       "2268      4                                               User   \n",
       "2269      4                                               User   \n",
       "2270      2                                                 DJ   \n",
       "\n",
       "                                              Vorschlag Binnen  \n",
       "0                                                  CISO      N  \n",
       "1     Verantwortliche bzw. Verantwortlicher für Info...      N  \n",
       "2                    Diplomiertes Krankenpflegepersonal      N  \n",
       "3     Unabhängige Bedienstetenschutzbeauftragte bzw....      N  \n",
       "4     Kontrakt- und Berichtswesenbeauftragte bzw. -b...      N  \n",
       "...                                                 ...    ...  \n",
       "2266                                   Köchin bzw. Koch      N  \n",
       "2267                                        Berühmtheit      N  \n",
       "2268                                   Userin bzw. User      N  \n",
       "2269                                          UserInnen      Y  \n",
       "2270                                      DJane bzw. DJ      N  \n",
       "\n",
       "[2268 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "execution_count": 138
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "source": [
    "data_dict: Dict[str, List[str]] = {}\n",
    "for (_, _, pattern, suggestion, binnenI) in df.to_records():\n",
    "    if binnenI == \"Y\":\n",
    "        suggestion = re.sub(r\"([a-zäöüß])I\", r\"\\1*i\", suggestion)\n",
    "    if pattern in data_dict.keys():\n",
    "        data_dict[pattern].append(suggestion)\n",
    "    else:\n",
    "        data_dict[pattern] = [suggestion]\n",
    "\n",
    "data = []\n",
    "for key, val in data_dict.items():\n",
    "    data.append({\n",
    "                \"pattern\": key,\n",
    "                \"postag\": None,\n",
    "                \"suggestions\": val,\n",
    "                \"url\": \"https://www.data.gv.at/katalog/dataset/15d6ede8-f128-4fcd-aa3a-4479e828f477\"\n",
    "            })\n",
    "data[-2]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'pattern': 'User',\n",
       " 'postag': None,\n",
       " 'suggestions': ['Userin bzw. User', 'User*innen'],\n",
       " 'url': 'https://www.data.gv.at/katalog/dataset/15d6ede8-f128-4fcd-aa3a-4479e828f477'}"
      ]
     },
     "metadata": {},
     "execution_count": 139
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "source": [
    "datasets.append(data)\n",
    "data = None"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## The _DeReKo_ data set\n",
    "\n",
    "We extract some data from the \"Deutsche ReferenzKorpus\". \n",
    "\n",
    "Queries:\n",
    "- Internal I: `:Ab:*?Innen`: 241k tokens, 18k types (`:Ab:*?In` and `:Ab:#REG(^[A-ZÄÖÜ][a-zäöüß]+In(nen)?$)` throw errors)\n",
    "- Slash: `#REG(^[A-ZÄÖÜ][a-zäöüß]+\\/in(nen)?$)`: 136k tokens, 9k types\n",
    "- Star: `#REG(^[A-ZÄÖÜ][a-zäöüß]+\\*in(nen)?$)`: 48k tokens, 5k types\n",
    "- Colon: `#REG(^[A-ZÄÖÜ][a-zäöüß]+:in(nen)?$)`: 10k tokens, 3k types\n",
    "- Underscore: `#REG(^[A-ZÄÖÜ][a-zäöüß]+_in(nen)?$)`: 3k tokens, 1k types\n",
    "- Interpunct: `#REG(^[A-ZÄÖÜ][a-zäöüß]+·in(nen)?$)`: 4(!) matches\n",
    "- Brackets: `*?\\(In\\)`, `*?\\(Innen\\)`, `#REG(\\(in(nen)\\))` and similar queries throw errors"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "There is no machine-readable download on DeReKo to our knowledge, so we process the files a bit:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "source": [
    "def dereko_to_csv(filename: str):\n",
    "    text = open(path.join(data_dir, \"dereko\", filename + '.txt')).read()\n",
    "    lines = text.split(\"\\n\")[20:]\n",
    "    rx = r\"[A-ZÄÖÜ][a-zäöüß]{3,}[/*:_·()]?[Ii]n(nen)?\"\n",
    "    words = [re.match(rx, line)[0] for line in lines if re.match(rx, line)]\n",
    "    open(path.join(data_dir, \"dereko\", filename + '.csv'), \"w\").write(\"\\n\".join(words))\n",
    "    return words"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "source": [
    "dereko_to_csv(\"internal-i\")[:5]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['AachenerInnen',\n",
       " 'AbbiegerInnen',\n",
       " 'AbbrecherInnen',\n",
       " 'AbeitsplatzbesitzerInnen',\n",
       " 'AbendländerInnen']"
      ]
     },
     "metadata": {},
     "execution_count": 142
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "source": [
    "dereko_to_csv(\"colon\")[:5]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['Abenteurer:innen',\n",
       " 'Abfahrt:In',\n",
       " 'Abiturient:innen',\n",
       " 'Abkommen:In',\n",
       " 'Ablehner:innen']"
      ]
     },
     "metadata": {},
     "execution_count": 143
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "source": [
    "dereko_lists = [dereko_to_csv(a) for a in [\"colon\", \"internal-i\", \"interpunct\", \"slash\", \"star\", \"underscore\"]]\n",
    "united: Dict[str, List[str]] = {}\n",
    "for l in dereko_lists:\n",
    "    for word in l:\n",
    "        if re.match(r\".*[Ii]n$\", word): # restrict to singular\n",
    "            key = re.sub(r\"[/*:_·()]?[Ii]n(nen)?$\", \"\", word)\n",
    "            val = re.sub(r\"[/*:_·()]?[Ii]n\", \"*in\", word)\n",
    "            if key in united.keys():\n",
    "                united[key].append(word)\n",
    "            else:\n",
    "                united[key] = [word]\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "source": [
    "data = []\n",
    "for key, val in united.items():\n",
    "    data.append({\n",
    "                \"pattern\": key,\n",
    "                \"postag\": None,\n",
    "                \"suggestions\": val,\n",
    "                \"url\": \"\"\n",
    "            })"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "source": [
    "datasets.append(data)\n",
    "data = None"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Because we cannot use regular expressions to enhance the \"internal i\" query directly on DeReKo (due to issues with case sensitivity), we perform some postprocessing for the results."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## The _retext equality_ data set"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We skip this data set for now because many of the rules cannot be transformed to simple replacement rules."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "source": [
    "# responses = {}\n",
    "# for topic in topics:\n",
    "#     responses[topic] = requests.get(\"https://raw.githubusercontent.com/retextjs/retext-equality/main/data/en/{}.yml\".format(topic)).text\n",
    "    "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "source": [
    "# for topic in topics:\n",
    "#     data = yaml.safe_load(responses[topic])\n",
    "#     for row in data:\n",
    "#         considerate = row[\"considerate\"]\n",
    "#         inconsiderate = row[\"inconsiderate\"]\n",
    "#         if type(considerate) == str:\n",
    "#             rules[considerate] = inconsiderate\n",
    "#         elif type(considerate) == list:\n",
    "#             for phrase in considerate:\n",
    "#                 rules[phrase] = inconsiderate"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "source": [
    "# open(path.join(\"data\", \"retext_equality_raw.yaml\"), \"w\").write(yaml.dump(data))\n",
    "# datasets.append(data)\n",
    "# data = None"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Custom rules"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We add some custom rules that we have written ourselves, inspired in part by the _retext-equality_ data set. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "source": [
    "custom_xml = open(path.join(data_dir, \"custom_list_disability.xml\")).read()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Conversion to proper LanguageTool XML format\n",
    "\n",
    "The LanguageTool rule format is described [over here](https://web.archive.org/web/20210910183442/https://dev.languagetool.org/development-overview) and [here](https://dev.languagetool.org/tips-and-tricks)."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We devise a function to convert a _geschickt gendern_ entry to a XML LanguageTool entry."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "source": [
    "def rule_to_xml(pattern: str, postag: Optional[str], suggestions: List[str], url: str) -> str:\n",
    "    id = re.sub(\"[^A-ZÄÖÜa-zäöüß_]\", \"\", re.sub(\"\\s\", \"_\", \"_\".join([pattern, (postag or \"\")])))\n",
    "    postag_attribute = 'postag=\"{}\" '.format(postag) if postag is not None else \"\"\n",
    "    replaced_tokens = \"\".join([\n",
    "        '<token inflected=\"yes\" {}postag_regexp=\"yes\">{}</token>'.format(postag_attribute, token) \n",
    "        for token in pattern.split(\" \")])\n",
    "    suggestions_ = \"\\n\\t\\t\".join([\"<suggestion>{}</suggestion>\".format(s) for s in suggestions])\n",
    "    return \"\"\"\n",
    "    <rule id=\"{id}\" name=\"{pattern}\">\n",
    "        <pattern>{replaced_tokens}</pattern>\n",
    "        <message>\n",
    "        Mit dem generischen Maskulinum werden nicht alle Geschlechter gleichermaßen assoziiert. Vielleicht passt einer der folgenden neutralen Begriffe besser: {suggestions}\n",
    "        </message>\n",
    "        <url>{url}</url>\n",
    "        <short>Generisches Maskulinum</short>\n",
    "        <example correction=\"{s}\"><marker>{pattern}</marker></example>\n",
    "    </rule>\n",
    "    \"\"\".format(id=id, pattern=pattern, replaced_tokens=replaced_tokens, suggestions=suggestions_, s=suggestions[0], url=url)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "source": [
    "xml = custom_xml + \"\\n\\n\" + \"\".join([\"\".join([rule_to_xml(**datum) for datum in dataset]) for dataset in datasets])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Injecting the rules to the existing LanguageTool rule file"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "source": [
    "grammar_path = path.join(languagetool_path, \"org\", \"languagetool\", \"rules\", \"de\") # path of the German grammar files within the LanguageTool release\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "source": [
    "custom_filename = \"grammar_custom.xml\"\n",
    "open(path.join(data_dir, custom_filename), \"w\").write(xml)\n",
    "open(path.join(grammar_path, custom_filename), \"w\").write(xml)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "5016104"
      ]
     },
     "metadata": {},
     "execution_count": 154
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "source": [
    "# Use backup file if available (see comments below)\n",
    "if path.isfile(path.join(grammar_path, \"grammar.xml.old\")):\n",
    "  old_xml = open(path.join(grammar_path, \"grammar.xml.old\")).read()\n",
    "else:\n",
    "  old_xml = open(path.join(grammar_path, \"grammar.xml\")).read()\n",
    "  # Save backup of the old grammar file.\n",
    "  open(path.join(grammar_path, \"grammar.xml.old\"), \"w\").write(old_xml)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "And then we inject the category tag with its contents to the existing LanguageTool rule XML file:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "source": [
    "new_xml = old_xml.replace(\n",
    "        \"<!DOCTYPE rules [\", \n",
    "        '<!DOCTYPE rules [ \\n\\t<!ENTITY UserRules SYSTEM \"file:///{}\">'.format(path.abspath(path.join(grammar_path, custom_filename)))\n",
    "    ).replace(\n",
    "        \"</rules>\", \n",
    "        '<category id=\"DIVERSITY_SENSITIVE_LANGUAGE\" name=\"Erweiterung für diversitätssensible Sprache\">\\n&UserRules;\\n</category>\\n</rules>'\n",
    "    )\n",
    "\n",
    "# Replace with file where the new rules have been added.\n",
    "open(path.join(grammar_path, \"grammar.xml\"), \"w\").write(new_xml)\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "3174368"
      ]
     },
     "metadata": {},
     "execution_count": 156
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Validating and using the rules"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Running the LanguageTool rule validation:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "source": [
    "# subprocess.run([\"./testrules.sh\", \"de\"], cwd=languagetool_path)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Starting LanguageTool:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "source": [
    "# subprocess.run([\"java\", \"-jar\", path.join(languagetool_path, \"languagetool.jar\")])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2021-09-13 19:24:31 +0000 Setting up thread pool with 10 threads\n",
      "2021-09-13 19:24:31 +0000 Starting LanguageTool 5.4 (build date: 2021-06-25 10:24:16 +0000, ba046d4) server on http://localhost:8081...\n",
      "2021-09-13 19:24:31 +0000 Server started\n",
      "2021-09-13 19:26:13 +0000 Stopping server...\n",
      "2021-09-13 19:26:18 +0000 Server stopped\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "CompletedProcess(args=['java', '-jar', '../languagetool/LanguageTool-5.4/languagetool.jar'], returncode=0)"
      ]
     },
     "metadata": {},
     "execution_count": 159
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## TODO\n",
    "\n",
    "- For the DeReKo corpus, only singular words are used so far\n",
    "- The different datasets are not unified in one dictionary\n",
    "- Finding the correct masculina of the DeReKo corpus could be improved (xxx*innen -> xxx | xxxen)\n",
    "- Data about jobs and persons + auto-gendering from various sources could be added"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0b0dc9e761e59a4e4ede0a269ef63c2a98e0858221cbee9c4c0da7c9f303cec2"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.7 64-bit ('diversity-B6CKKqL5-py3.9': poetry)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}