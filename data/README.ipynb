{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Creating the rule set"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "This notebook is about creating the rule set for diversity sensitive suggestions for the LanguageTool server. Some sources will be pulled from the internet and will be processed to fit the format as well as possible."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The notebook uses [Poetry](https://python-poetry.org/) for reproducibility. For running the notebook in an environment where the appropriate dependencies are installed, run `poetry install` and then `poetry run jupyter notebook` to start the notebook server."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import cache_magic\n",
    "import copy_files\n",
    "import datetime\n",
    "import io\n",
    "from os import path\n",
    "import pandas as pd\n",
    "import random\n",
    "import re\n",
    "import requests    \n",
    "import subprocess\n",
    "import spacy\n",
    "from typing import *\n",
    "import wayback\n",
    "import yaml"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "%cache magic is now registered in ipython\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "data_dir = \"wordlists\" # where the downloaded and processed data will be saved\n",
    "fetch_data = False # whether to re-download the files"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "def log(a, x):\n",
    "    # Helper function for functionally logging things.\n",
    "    print(a)\n",
    "    print(x)\n",
    "    return x"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "nlp = spacy.load(\"de_core_news_sm\")\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "def number(s: str) -> List[str]:\n",
    "    return nlp(s)[0].morph.get(\"Number\")\n",
    "\n",
    "assert number(\"Bundeskanzlerin\") == [\"Sing\"]\n",
    "assert number(\"Bundeskanzlerinnen\") == [\"Plur\"]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "def is_word(word: str) -> bool:\n",
    "    return True\n",
    "#     return len(gn.sysnsets(word)) > 0\n",
    "\n",
    "# assert is_word(\"Baum\") == True\n",
    "# assert is_word(\"Bäum\") == False"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "data = {\n",
    "    \"sg\": {},\n",
    "    \"pl\": {},\n",
    "}\n",
    "\n",
    "def strip_spaces(a):\n",
    "    s = re.sub(\"  +|\\\"|'\", \" \", a)\n",
    "    a = re.sub(\"^ | $|[.,:;!?]\", \"\", a)\n",
    "    return a\n",
    "\n",
    "def add_to_data(pattern, numerus, suggestions):\n",
    "    pattern = strip_spaces(pattern)\n",
    "    if numerus == \"sg\":\n",
    "        add_to_dict(pattern, suggestions, data[\"sg\"])\n",
    "    elif numerus == \"pl\":\n",
    "        add_to_dict(pattern, suggestions, data[\"pl\"])\n",
    "    elif numerus == \"unknown\":\n",
    "        if \"Sing\" in number(pattern):\n",
    "            add_to_data(pattern, \"sg\", suggestions)\n",
    "        if \"Plur\" in number(pattern):\n",
    "            add_to_data(pattern, \"pl\", suggestions)\n",
    "\n",
    "def add_to_dict(key, vals: List[str], dic):\n",
    "    if key in dic.keys():\n",
    "        for val in vals:\n",
    "            if not val in dic[key]:\n",
    "                dic[key].append(val)\n",
    "    else:\n",
    "        dic[key] = vals"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## The data set by _geschickt gendern_"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "wb = client = wayback.WaybackClient()\n",
    "%cache mem = wb.get_memento(\"https://geschicktgendern.de/download/1642/\", datetime=datetime.datetime(2021, 9, 11, tzinfo=datetime.timezone.utc), exact=False)\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "loading cached value for variable 'mem'. Time since pickling  0:00:11.597049\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "df = pd.read_excel(mem.content, header=None, names=[\"ungendered\", \"gendered\"], skiprows=3, usecols=[1,2])\n",
    "df.sort_values(by=\"ungendered\")\n",
    "df"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ungendered</th>\n",
       "      <th>gendered</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;div id=\"A\"&gt;&lt;b&gt;A&lt;/b&gt;&lt;div&gt;</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Abbrecherquote</td>\n",
       "      <td>Abbruchquote</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Abenteurer (sg.)</td>\n",
       "      <td>Waghals; abenteuerliebende Person; abenteuerlu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Abgänger</td>\n",
       "      <td>absolvierende Person; Abschluss innehabende Pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Abiturient</td>\n",
       "      <td>Abitur ablegende Person; Person, die Abitur macht</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1814</th>\n",
       "      <td>Zuschauer (pl.)</td>\n",
       "      <td>Publikum; Zuschauende</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1815</th>\n",
       "      <td>Zuschauerquote</td>\n",
       "      <td>Einschaltquote</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1816</th>\n",
       "      <td>Zuschauerzahl</td>\n",
       "      <td>Publikumszahl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1817</th>\n",
       "      <td>Zuständiger</td>\n",
       "      <td>zuständige Person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1818</th>\n",
       "      <td>Zuwanderer (pl.)</td>\n",
       "      <td>Zugewanderte; Personen mit Migrationshintergru...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1819 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     ungendered  \\\n",
       "0     <div id=\"A\"><b>A</b><div>   \n",
       "1                Abbrecherquote   \n",
       "2              Abenteurer (sg.)   \n",
       "3                      Abgänger   \n",
       "4                    Abiturient   \n",
       "...                         ...   \n",
       "1814            Zuschauer (pl.)   \n",
       "1815             Zuschauerquote   \n",
       "1816              Zuschauerzahl   \n",
       "1817                Zuständiger   \n",
       "1818           Zuwanderer (pl.)   \n",
       "\n",
       "                                               gendered  \n",
       "0                                                   NaN  \n",
       "1                                          Abbruchquote  \n",
       "2     Waghals; abenteuerliebende Person; abenteuerlu...  \n",
       "3     absolvierende Person; Abschluss innehabende Pe...  \n",
       "4     Abitur ablegende Person; Person, die Abitur macht  \n",
       "...                                                 ...  \n",
       "1814                              Publikum; Zuschauende  \n",
       "1815                                     Einschaltquote  \n",
       "1816                                      Publikumszahl  \n",
       "1817                                  zuständige Person  \n",
       "1818  Zugewanderte; Personen mit Migrationshintergru...  \n",
       "\n",
       "[1819 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We drop rows like the first one, where there is merely some HTML description but no value."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "# df = df[df[\"gendered\"].notna()]\n",
    "# df.to_csv(path.join(data_dir, \"geschicktgendern.csv\"), index=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "df = pd.read_csv(path.join(data_dir, \"geschicktgendern.csv\"))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We convert the singular / plural annotations to part-of-speech tags for LanguageTool:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "df.loc[13]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "ungendered                     Abteilungsleiter (pl.)\n",
       "gendered      Abteilungsleitungen; Abteilungsleitende\n",
       "Name: 13, dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We see that some suggestions are annotated by HTML, for example with the annotation that there is no good suggestion yet. This is too complicated for us to handle, so we will drop such suggestions."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The `gendered` column often contains multiple variants that are separated by a semicolon. We want to capture this."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Some rows contain values that include formatting. We drop these values, but not the whole row."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "records = df.to_records()\n",
    "def numerus(key: Optional[str]) -> str:\n",
    "    numerus = re.search(\"\\(.*(sg|pl)\\.\\)\", key)\n",
    "    if numerus:\n",
    "        if numerus[1] == \"sg\":\n",
    "            return \"sg\"\n",
    "        if numerus[1] == \"pl\":\n",
    "            return \"pl\"\n",
    "    else: \n",
    "        return \"unknown\"\n",
    "def complicated(a):\n",
    "    # the rule includes extra annotation in brackets or HTML and is thus too complicated for us to use\n",
    "    return any([b in a for b in [\"<\", \"(\", \"[\", \"\\\"\", \"'\"]])\n",
    "i = 0\n",
    "for (_, key, val) in records:\n",
    "    unannotated_suggestions = [x for x in val.split(\"; \") if  not (complicated(x) or x == \"\")]\n",
    "    if not (complicated(key) or \"...\" in key) and len(unannotated_suggestions) > 0:\n",
    "        pattern =  re.sub(\" ?\\[.*\\]\", \"\", re.sub(\" ?\\(.*\\)\", \"\", key))\n",
    "        add_to_data(pattern, numerus(key), unannotated_suggestions)\n",
    "        i += 1\n",
    "print(\"This reduces the number of used rules from {} to {}.\".format(len(records), i))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "This reduces the number of used rules from 1792 to 943.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## The Microsoft / Vienna catalog"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "%cache mem = wb.get_memento(\"https://www.data.gv.at/katalog/dataset/15d6ede8-f128-4fcd-aa3a-4479e828f477/resource/804f6db1-add7-4480-b4d0-e52e61c48534/download/worttabelle.csv\", datetime=datetime.datetime(2021, 9, 13, tzinfo=datetime.timezone.utc), exact=False)\n",
    "text = re.sub(\";;\\r\\n\", \"\\n\", mem.content.decode(\"utf-8\"))\n",
    "df = pd.read_csv(io.StringIO(text))\n",
    "df = df[df[\"Hauptwort\"].notna()]\n",
    "df.to_csv(path.join(data_dir, \"vienna_catalog.csv\"), index=False)\n",
    "df"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "creating new value for variable 'mem'\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Laenge</th>\n",
       "      <th>Hauptwort</th>\n",
       "      <th>Vorschlag</th>\n",
       "      <th>Binnen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "      <td>Verantwortlicher für Informationssicherheit (C...</td>\n",
       "      <td>CISO</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Verantwortlicher für Informationssicherheit (C...</td>\n",
       "      <td>Verantwortliche bzw. Verantwortlicher für Info...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>45</td>\n",
       "      <td>Diplomierte Gesundheits- und Krankenschwester</td>\n",
       "      <td>Diplomiertes Krankenpflegepersonal</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>43</td>\n",
       "      <td>Unabhängiger Bedienstetenschutzbeauftragter</td>\n",
       "      <td>Unabhängige Bedienstetenschutzbeauftragte bzw....</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>39</td>\n",
       "      <td>Kontrakt- und Berichtswesenbeauftragter</td>\n",
       "      <td>Kontrakt- und Berichtswesenbeauftragte bzw. -b...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2266</th>\n",
       "      <td>4</td>\n",
       "      <td>Koch</td>\n",
       "      <td>Köchin bzw. Koch</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2267</th>\n",
       "      <td>4</td>\n",
       "      <td>Star</td>\n",
       "      <td>Berühmtheit</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2268</th>\n",
       "      <td>4</td>\n",
       "      <td>User</td>\n",
       "      <td>Userin bzw. User</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2269</th>\n",
       "      <td>4</td>\n",
       "      <td>User</td>\n",
       "      <td>UserInnen</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2270</th>\n",
       "      <td>2</td>\n",
       "      <td>DJ</td>\n",
       "      <td>DJane bzw. DJ</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2268 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Laenge                                          Hauptwort  \\\n",
       "0        50  Verantwortlicher für Informationssicherheit (C...   \n",
       "1        50  Verantwortlicher für Informationssicherheit (C...   \n",
       "2        45      Diplomierte Gesundheits- und Krankenschwester   \n",
       "3        43        Unabhängiger Bedienstetenschutzbeauftragter   \n",
       "4        39            Kontrakt- und Berichtswesenbeauftragter   \n",
       "...     ...                                                ...   \n",
       "2266      4                                               Koch   \n",
       "2267      4                                               Star   \n",
       "2268      4                                               User   \n",
       "2269      4                                               User   \n",
       "2270      2                                                 DJ   \n",
       "\n",
       "                                              Vorschlag Binnen  \n",
       "0                                                  CISO      N  \n",
       "1     Verantwortliche bzw. Verantwortlicher für Info...      N  \n",
       "2                    Diplomiertes Krankenpflegepersonal      N  \n",
       "3     Unabhängige Bedienstetenschutzbeauftragte bzw....      N  \n",
       "4     Kontrakt- und Berichtswesenbeauftragte bzw. -b...      N  \n",
       "...                                                 ...    ...  \n",
       "2266                                   Köchin bzw. Koch      N  \n",
       "2267                                        Berühmtheit      N  \n",
       "2268                                   Userin bzw. User      N  \n",
       "2269                                          UserInnen      Y  \n",
       "2270                                      DJane bzw. DJ      N  \n",
       "\n",
       "[2268 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "for (_, _, pattern, suggestion, binnenI) in df.to_records():\n",
    "    if binnenI == \"Y\":\n",
    "        suggestion = re.sub(r\"([a-zäöüß])I\", r\"\\1*i\", suggestion)\n",
    "    if not complicated(pattern) or complicated(suggestion):\n",
    "        if re.findall(\"[iI]n($| )\", suggestion) != []:\n",
    "            add_to_data(pattern, \"sg\", [suggestion])\n",
    "        elif re.findall(\"[iI]nnen$\", suggestion) != []:\n",
    "            add_to_data(pattern, \"pl\", [suggestion])\n",
    "        else:\n",
    "            add_to_data(pattern, \"unknown\", [suggestion])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## The _DeReKo_ data set\n",
    "\n",
    "We extract some data from the \"Deutsche ReferenzKorpus\". \n",
    "\n",
    "Queries:\n",
    "- Internal I: `:Ab:*?Innen`: 241k tokens, 18k types (`:Ab:*?In` and `:Ab:#REG(^[A-ZÄÖÜ][a-zäöüß]+In(nen)?$)` throw errors)\n",
    "- Slash: `#REG(^[A-ZÄÖÜ][a-zäöüß]+\\/in(nen)?$)`: 136k tokens, 9k types\n",
    "- Star: `#REG(^[A-ZÄÖÜ][a-zäöüß]+\\*in(nen)?$)`: 48k tokens, 5k types\n",
    "- Colon: `#REG(^[A-ZÄÖÜ][a-zäöüß]+:in(nen)?$)`: 10k tokens, 3k types\n",
    "- Underscore: `#REG(^[A-ZÄÖÜ][a-zäöüß]+_in(nen)?$)`: 3k tokens, 1k types\n",
    "- Interpunct: `#REG(^[A-ZÄÖÜ][a-zäöüß]+·in(nen)?$)`: 4(!) matches\n",
    "- Brackets: `*?\\(In\\)`, `*?\\(Innen\\)`, `#REG(\\(in(nen)\\))` and similar queries throw errors"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "There is no machine-readable download on DeReKo to our knowledge, so we process the files a bit:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "match_properly_gendered_word = r\"[A-ZÄÖÜ][a-zäöüß]{3,}(([/*:_·(]in(nen)?\\)?)|In(nen)?)\"\n",
    "\n",
    "def is_properly_gendered_word(word: str) -> bool:\n",
    "    return re.findall(r\"^[A-ZÄÖÜ][a-zäöüß]{3,}(([/*:_·(]in(nen)?\\)?)|In(nen)?)$\", word) != []\n",
    "\n",
    "assert is_properly_gendered_word(\"Bundeskanzler:innen\") == True\n",
    "assert is_properly_gendered_word(\"BundeskanzlerIn\") == True\n",
    "assert is_properly_gendered_word(\"Bundeskanzler*Innen\") == False"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "def dereko_to_csv(filename: str):\n",
    "    text = open(path.join(data_dir, \"dereko\", filename + '.txt')).read()\n",
    "    lines = text.split(\"\\n\")[20:]\n",
    "    words = [re.match(match_properly_gendered_word, line)[0] for line in lines if re.match(match_properly_gendered_word, line)]\n",
    "    open(path.join(data_dir, \"dereko\", filename + '.csv'), \"w\").write(\"\\n\".join(words))\n",
    "    return words\n",
    "\n",
    "assert 'Bundeskanzler*in' in dereko_to_csv(\"star\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "dereko_to_csv(\"internal-i\")[:5]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['AachenerInnen',\n",
       " 'AbbiegerInnen',\n",
       " 'AbbrecherInnen',\n",
       " 'AbeitsplatzbesitzerInnen',\n",
       " 'AbendländerInnen']"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "dereko_to_csv(\"colon\")[:5]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['Abenteurer:innen',\n",
       " 'Abiturient:innen',\n",
       " 'Ablehner:innen',\n",
       " 'Abnehmer:innen',\n",
       " 'Abonennt:innen']"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "def is_gendered_plural(word: str) -> str:\n",
    "    return re.findall(r\"[Ii]nnen\\)?$\", word) != []\n",
    "\n",
    "assert is_gendered_plural(\"Bundeskanzler*in\") == False\n",
    "assert is_gendered_plural(\"Bundesminister/in\") == False\n",
    "assert is_gendered_plural(\"Bundesminister*innen\") == True"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "def ungender(word: str) -> str:\n",
    "    return re.sub(r\"[/*:_·()]?[Ii]n(n(en))?$\", \"\", word)\n",
    "\n",
    "assert ungender(\"Bundeskanzler*in\") == \"Bundeskanzler\"\n",
    "assert ungender(\"Bundesminister*innen\") == \"Bundesminister\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "def regender(word: str, symbol: str) -> str:\n",
    "    # replace gender symbol with other gender symbol\n",
    "    return re.sub(r\"[/*:_·()]?-?[Ii]n(nen)?$\", r\"{}in\\1\".format(symbol), word)\n",
    "\n",
    "assert regender(\"Bundeskanzler*in\", \"*\") == \"Bundeskanzler*in\"\n",
    "assert regender(\"Bundeskanzler:in\", \"*\") == \"Bundeskanzler*in\"\n",
    "assert regender(\"Bundeskanzler_in\", \"*\") == \"Bundeskanzler*in\"\n",
    "assert regender(\"Bundeskanzler/in\", \"*\") == \"Bundeskanzler*in\"\n",
    "assert regender(\"Bundeskanzler/-in\", \"*\") == \"Bundeskanzler*in\"\n",
    "assert regender(\"Bundeskanzler·in\", \"*\") == \"Bundeskanzler*in\"\n",
    "assert regender(\"BundeskanzlerIn\", \"*\") == \"Bundeskanzler*in\"\n",
    "assert regender(\"BundesministerIn\", \"*\") == \"Bundesminister*in\"\n",
    "assert regender(\"BundesministerInnen\", \"*\") == \"Bundesminister*innen\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "count_dict = {}\n",
    "def add_to_count_dict(key, number, val):\n",
    "    if (key, number, val) in count_dict.keys():\n",
    "        count_dict[(key, number, val)] += 1\n",
    "    else:\n",
    "        count_dict[(key, number, val)] = 1"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "dereko_lists = [dereko_to_csv(a) for a in [\"colon\", \"internal-i\", \"interpunct\", \"slash\", \"star\", \"underscore\"]]\n",
    "for l in dereko_lists:\n",
    "    for word in l:\n",
    "        if is_properly_gendered_word(word):\n",
    "            key = ungender(word)\n",
    "            suggestion = regender(word, \"*\")\n",
    "            if is_gendered_plural(suggestion):\n",
    "                if is_word(key):\n",
    "                    add_to_count_dict(key, \"pl\", suggestion)\n",
    "                if is_word(key):\n",
    "                    add_to_count_dict(key + \"en\", \"pl\", suggestion)\n",
    "            else:  \n",
    "                add_to_count_dict(key, \"sg\", suggestion)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "dereko_unified = {}\n",
    "for (key, number, val), count in count_dict.items():\n",
    "    if count > 1:\n",
    "        add_to_dict(key, [val], dereko_unified)\n",
    "        add_to_data(key, number, [val])\n",
    "assert 'Bundeskanzler' in data[\"sg\"].keys()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "open(path.join(data_dir, \"dereko\", \"unified.csv\"), \"w\").write(\"\\n\".join(sorted([a[0] for a in dereko_unified.values()])))"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "134367"
      ]
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Because we cannot use regular expressions to enhance the \"internal i\" query directly on DeReKo (due to issues with case sensitivity), we perform some postprocessing for the results."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## The _retext equality_ data set"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We skip this data set for now because many of the rules cannot be transformed to simple replacement rules."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "# responses = {}\n",
    "# for topic in topics:\n",
    "#     responses[topic] = requests.get(\"https://raw.githubusercontent.com/retextjs/retext-equality/main/data/en/{}.yml\".format(topic)).text\n",
    "    "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "# for topic in topics:\n",
    "#     data = yaml.safe_load(responses[topic])\n",
    "#     for row in data:\n",
    "#         considerate = row[\"considerate\"]\n",
    "#         inconsiderate = row[\"inconsiderate\"]\n",
    "#         if type(considerate) == str:\n",
    "#             rules[considerate] = inconsiderate\n",
    "#         elif type(considerate) == list:\n",
    "#             for phrase in considerate:\n",
    "#                 rules[phrase] = inconsiderate"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "# open(path.join(\"data\", \"retext_equality_raw.yaml\"), \"w\").write(yaml.dump(data))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Custom rules"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We add some custom rules that we have written ourselves, inspired in part by the _retext-equality_ data set. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "custom_xml = open(path.join(data_dir, \"custom_list_disability.xml\")).read()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Conversion to proper LanguageTool XML format\n",
    "\n",
    "The LanguageTool rule format is described [over here](https://web.archive.org/web/20210910183442/https://dev.languagetool.org/development-overview) and [here](https://dev.languagetool.org/tips-and-tricks)."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We devise a function to convert a _geschickt gendern_ entry to a XML LanguageTool entry."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "re.findall(r\"\\w+|\\W+\", \"Wiener*innen\")"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['Wiener', '*', 'innen']"
      ]
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "def startupper(s: str) -> str:\n",
    "    return s[0].capitalize() + s[1:]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "assert startupper(\"absolvierende Person\") == \"Absolvierende Person\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "source": [
    "def rule_to_xml(pattern: str, numerus: str, suggestions: List[str]) -> str:\n",
    "    id = re.sub(\"\\s\", \"_\", pattern + \"_\" + numerus)\n",
    "    id = re.sub(\"[^A-ZÄÖÜa-zäöüß_]\", \"\", id)\n",
    "    if numerus == \"sg\":\n",
    "        postag_attributes = 'postag=\".*:SIN:.*\" postag_regexp=\"yes\" '\n",
    "    elif numerus == \"pl\":\n",
    "        postag_attributes = 'postag=\".*:PLU:.*\" postag_regexp=\"yes\" '\n",
    "    replaced_tokens = \"\".join([\n",
    "        '<token inflected=\"yes\" {}>{}</token>'.format(postag_attributes, token) \n",
    "        for token in pattern.split(\" \")])\n",
    "    suggestions_ = \",\\n\\t\\t\".join([\"<suggestion>{}</suggestion>\".format(s) for s in suggestions])\n",
    "    antipatterns = \"\\n\\t\\t\".join(\n",
    "        [\"<antipattern>\\n\\t\\t{}\\n\\t\\t</antipattern>\".format(\"\\n\\t\\t\".join(\n",
    "            ['<token inflected=\"yes\">{}</token>'.format(token) for token in re.findall(r\"\\w+|[.,:;*_·/]\", s)]\n",
    "        )) for s in suggestions])\n",
    "    corrections = \"|\".join([startupper(s) for s in suggestions])\n",
    "    return \"\"\"\n",
    "    <rule id=\"{id}\" name=\"{pattern}\">\n",
    "        {antipatterns}\n",
    "        <pattern>{replaced_tokens}</pattern>\n",
    "        <message>\n",
    "        Mit dem generischen Maskulinum werden nicht alle Geschlechter gleichermaßen assoziiert. Vielleicht passt einer der folgenden neutralen Begriffe besser: \n",
    "        {suggestions}\n",
    "        </message>\n",
    "        <short>Generisches Maskulinum</short>\n",
    "        <example correction=\"{corrections}\"><marker>{pattern}</marker></example>\n",
    "    </rule>\n",
    "    \"\"\".format(id=id, pattern=pattern, antipatterns=antipatterns, replaced_tokens=replaced_tokens, suggestions=suggestions_, corrections=corrections)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "source": [
    "# print(rule_to_xml(\"Wiener\", \"pl\", data[\"sg\"][\"pl\"]))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "source": [
    "xml = \"\"\n",
    "for numerus in [\"sg\", \"pl\"]:\n",
    "    xml += custom_xml + \"\\n\\n\" + \"\".join([rule_to_xml(key, numerus, val) for key, val in data[numerus].items()])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Injecting the rules to the existing LanguageTool rule file"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "source": [
    "custom_filename = \"grammar_custom.xml\"\n",
    "open(path.join(data_dir, custom_filename), \"w\").write(xml)\n",
    "copy_files.copy_files()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Validating and using the rules"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Running the LanguageTool rule validation:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "source": [
    "# subprocess.run([\"./testrules.sh\", \"de\"], cwd=languagetool_path)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Starting LanguageTool:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "source": [
    "# subprocess.run([\"java\", \"-jar\", path.join(languagetool_path, \"languagetool.jar\")])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cd4fe399c72e787a9720dce887caf1dc09a63b486e10200170cacef8df86bf0f"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.7 64-bit ('diversity-1gIIt_8f-py3.9': poetry)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}